# Transhuge

æ¶‰åŠæ–‡ä»¶ huge_memory.c å’Œ khugepaged.c

- [ ] PageDoubleMap
- [x] THP only support PMD ? so can it support more than 2M space (21bit) ?

ä½¿ç”¨ transparent hugepage çš„åŸå› :
1. TLB çš„è¦†ç›–æ›´å¤§ï¼Œå¯ä»¥é™ä½ TLB miss rate
3. hugepage çš„å‡ºç°è®©åŸå…ˆçš„ page walk çš„è·¯å¾„å˜çŸ­äº†

å‡ ä¸ª THP éœ€è¦è€ƒè™‘çš„æ ¸å¿ƒé—®é¢˜:
1. swap
2. reference çš„é—®é¢˜
3. split å’Œ merge

1. rmap å¦‚ä½•æ”¯æŒ thp
  - page_add_anon_rmap ä¹‹ç±»çš„ä½ç½®ç»´æŒ compound page çš„è®¡æ•°
2. thp page æ˜¯ PageLRU çš„å—?
  - æ˜¯çš„ï¼Œä¾‹å¦‚ move_folios_to_lru
3. å¯ä»¥ä¸»åŠ¨é‡Šæ”¾æ‰ thp ä¸ºæ™®é€šé¡µå—?
  - å¯ä»¥ï¼Œä¾‹å¦‚ä½¿ç”¨ madvise å’Œ prctl å¯ä»¥é‡Šæ”¾æŒ‡å®šè¿›ç¨‹çš„ï¼Œæˆ–è€…ç‰¹å®š vma çš„
  - ä½†æ˜¯ï¼Œä¸å­˜åœ¨ä¸€ä¸‹å­é‡Šæ”¾æ•´ä¸ªç³»ç»Ÿçš„ transhuge çš„è¡Œä¸º

## å†…æ ¸æ–‡æ¡£
[ç”¨æˆ·æ‰‹å†Œ](https://www.kernel.org/doc/html/latest/admin-guide/mm/transhuge.html)

The THP behaviour is controlled via `sysfs` interface and using `madvise(2)` and `prctl(2)` system calls.

1. å…¶ä¸­ prctl å¯ä»¥è®©ä¸€ä¸ªç¨‹åºç›´æ¥ disable æ‰ hugepage ï¼Œä»è€Œè§„é¿ç³»ç»Ÿçš„è®¾ç½®ï¼Œå…·ä½“å‚è€ƒ `PR_SET_THP_DISABLE`
2. shmem_enabled : The mount is used for SysV SHM, memfds, shared anonymous mmaps (of /dev/zero or MAP_ANONYMOUS), GPU drivers' DRM objects, Ashmem.

åœ¨ /sys/kernel/mm/transparent_hugepage/ ä¸‹

```txt
â”œâ”€â”€ defrag
â”œâ”€â”€ enabled
â”œâ”€â”€ hpage_pmd_size
â”œâ”€â”€ khugepaged
â”‚Â Â  â”œâ”€â”€ alloc_sleep_millisecs
â”‚Â Â  â”œâ”€â”€ defrag
â”‚Â Â  â”œâ”€â”€ full_scans
â”‚Â Â  â”œâ”€â”€ max_ptes_none
â”‚Â Â  â”œâ”€â”€ max_ptes_shared
â”‚Â Â  â”œâ”€â”€ max_ptes_swap
â”‚Â Â  â”œâ”€â”€ pages_collapsed
â”‚Â Â  â”œâ”€â”€ pages_to_scan
â”‚Â Â  â””â”€â”€ scan_sleep_millisecs
â”œâ”€â”€ shmem_enabled
â””â”€â”€ use_zero_page
```
/tmp çš„ hugepage æ¨¡å‹æ˜¯ mount çš„æ—¶å€™ç¡®å®šï¼Œä½†æ˜¯ shmat() å’Œ anon share æ˜¯é€šè¿‡è¿™ä¸ªæ¥å£çš„

ğŸ§€  cat shmem_enabled
always within_size advise [never] deny force

ğŸ§€  cat defrag
always defer defer+madvise [madvise] never

ğŸ§€  cat enabled
always madvise [never]

## TODO
```c
/*
 * By default, transparent hugepage support is disabled in order to avoid
 * risking an increased memory footprint for applications that are not
 * guaranteed to benefit from it. When transparent hugepage support is
 * enabled, it is for all mappings, and khugepaged scans all mappings.
 * Defrag is invoked by khugepaged hugepage allocations and by page faults
 * for all hugepage allocations.
 */
unsigned long transparent_hugepage_flags __read_mostly =
#ifdef CONFIG_TRANSPARENT_HUGEPAGE_ALWAYS
	(1<<TRANSPARENT_HUGEPAGE_FLAG)|
#endif
#ifdef CONFIG_TRANSPARENT_HUGEPAGE_MADVISE
	(1<<TRANSPARENT_HUGEPAGE_REQ_MADV_FLAG)|
#endif
	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_REQ_MADV_FLAG)|
	(1<<TRANSPARENT_HUGEPAGE_DEFRAG_KHUGEPAGED_FLAG)|
	(1<<TRANSPARENT_HUGEPAGE_USE_ZERO_PAGE_FLAG);
```

- [ ] page cache can't work with THP ?
- [ ] éªŒè¯ shmem_enabled çš„è¯´æ³•?

## defrag
  - [ ] /sys/kernel/mm/transparent_hugepage/defrag çš„ always æ— æ³•ç†è§£ï¼Œæˆ–è€…è¯´ï¼Œä»€ä¹ˆæ—¶å€™åº”è¯¥è§¦å‘ defrag, ä¸æ˜¯åˆ†é…çš„æ—¶å€™å°±æ˜¯å†³å®šäº†å— ?
- [ ] THP has to defrag pages, so check the compaction.c and find out how thp deal with it !
  - [ ] how defrag wake kcompactd ?

## page cache
- [ ] git show d68eccad370665830e16e5c77611fde78cd749b3
- [ ] åˆ†æä¸‹ `__filemap_add_folio`

[Transparent huge pages for filesystems](https://lwn.net/Articles/789159/)

> It is using the [Binary Optimization and Layout Tool (BOLT)](https://github.com/facebookincubator/BOLT) to profile its code in order to identify the hot functions. Those functions are collected up into an 8MB region in the generated executable.

## [ ] swap
é¡ºç€ CONFIG_THP_SWAP æ‰¾æ‰¾

## shmem hugepage : è®© tmpfs ä½¿ç”¨ä¸Š hugepage
https://stackoverflow.com/questions/67991417/how-to-use-hugepages-with-tmpfs

```sh
sudo mount -t tmpfs -osize=6G,mode=1777,huge=always tmpfs mem
```

mount çš„è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªè°ƒç”¨:
```txt
#0  shmem_parse_one (fc=0xffff8881424ebc00, param=0xffffc90001247e50) at mm/shmem.c:3437
#1  0xffffffff8139c8bb in vfs_parse_fs_param (param=0xffffc90001247e50, fc=0xffff8881424ebc00) at fs/fs_context.c:146
#2  vfs_parse_fs_param (fc=0xffff8881424ebc00, param=0xffffc90001247e50) at fs/fs_context.c:127
#3  0xffffffff8139c9a2 in vfs_parse_fs_string (fc=fc@entry=0xffff8881424ebc00, key=key@entry=0xffffffff8284d0eb "source", value=value@entry=0xffff888144681f58 "tmpfs", v_size=<optimized out>) at fs/fs_context.c:184
#4  0xffffffff8138588b in do_new_mount (data=0xffff888147ac3000, name=0xffff888144681f58 "tmpfs", mnt_flags=32, sb_flags=<optimized out>, fstype=0x20 <fixed_percpu_data+32> <error: Cannot access memory at address 0x20>, path=0xffffc90001247ef8) at fs/namespace.c:3034
#5  path_mount (dev_name=dev_name@entry=0xffff888144681f58 "tmpfs", path=path@entry=0xffffc90001247ef8, type_page=type_page@entry=0xffff888144681f18 "tmpfs", flags=<optimized out>, flags@entry=3236757504, data_page=data_page@entry=0xffff888147ac3000) at fs/namespace.c:3370
#6  0xffffffff81386162 in do_mount (data_page=0xffff888147ac3000, flags=3236757504, type_page=0xffff888144681f18 "tmpfs", dir_name=0x563274087540 "/home/martins3/g", dev_name=0xffff888144681f58 "tmpfs") at fs/namespace.c:3383
#7  __do_sys_mount (data=<optimized out>, flags=3236757504, type=<optimized out>, dir_name=0x563274087540 "/home/martins3/g", dev_name=<optimized out>) at fs/namespace.c:3591
#8  __se_sys_mount (data=<optimized out>, flags=3236757504, type=<optimized out>, dir_name=94774695064896, dev_name=<optimized out>) at fs/namespace.c:3568
#9  __x64_sys_mount (regs=<optimized out>) at fs/namespace.c:3568
#10 0xffffffff81f4270b in do_syscall_x64 (nr=<optimized out>, regs=0xffffc90001247f58) at arch/x86/entry/common.c:50
#11 do_syscall_64 (regs=0xffffc90001247f58, nr=<optimized out>) at arch/x86/entry/common.c:80
#12 0xffffffff8200009b in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:120
```

1. æ˜¾ç¤ºçš„ mount :
```txt
#0  shmem_fill_super (sb=0xffff8883d8af0000, fc=0xffff888104de2600) at mm/shmem.c:3753
#1  0xffffffff813cb606 in vfs_get_super (fc=0xffff888104de2600, reconf=<optimized out>, test=<optimized out>, fill_super=0xffffffff81300550 <shmem_fill_super>) at fs/super.c:1128
#2  0xffffffff813c92e1 in vfs_get_tree (fc=0xffff8883d8af0000, fc@entry=0xffff888104de2600) at fs/super.c:1489
#3  0xffffffff813f6157 in do_new_mount (data=0xffff88811d513000, name=0xffff88810006ec58 "tmpfs", mnt_flags=32, sb_flags=<optimized out>, fstype=0x20 <fixed_percpu_data+32> <error: Cannot access memory at address 0x20>, path=0xffffc900431ebef8) at fs/namespace.c:3145
#4  path_mount (dev_name=dev_name@entry=0xffff88810006ec58 "tmpfs", path=path@entry=0xffffc900431ebef8, type_page=type_page@entry=0xffff88810006ec50 "tmpfs", flags=<optimized out>, flags@entry=0, data_page=data_page@entry=0xffff88811d513000) at fs/namespace.c:3475
#5  0xffffffff813f6a16 in do_mount (data_page=0xffff88811d513000, flags=0, type_page=0xffff88810006ec50 "tmpfs", dir_name=0x55b015d3c540 "/root/tmp", dev_name=0xffff88810006ec58 "tmpfs") at fs/namespace.c:3488
#6  __do_sys_mount (data=<optimized out>, flags=0, type=<optimized out>, dir_name=0x55b015d3c540 "/root/tmp", dev_name=<optimized out>) at fs/namespace.c:3697
#7  __se_sys_mount (data=<optimized out>, flags=0, type=<optimized out>, dir_name=94214768805184, dev_name=<optimized out>) at fs/namespace.c:3674
#8  __x64_sys_mount (regs=<optimized out>) at fs/namespace.c:3674
#9  0xffffffff82189c3c in do_syscall_x64 (nr=<optimized out>, regs=0xffffc900431ebf58) at arch/x86/entry/common.c:50
#10 do_syscall_64 (regs=0xffffc900431ebf58, nr=<optimized out>) at arch/x86/entry/common.c:80
#11 0xffffffff822000ae in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:120
```
2. shmem_init : ä¸º anon shared å’Œ shmem çš„æ„å»ºçš„ï¼Œç”¨æˆ·æ€çœ‹ä¸åˆ°ã€‚

#### THP kernel
- [ ] å†…æ ¸æ€åˆ†æ: é€æ˜çš„æ€§è´¨åœ¨äº `__handle_mm_fault` ä¸­é—´å°±å¼€å§‹æ£€æŸ¥æ˜¯å¦å¯ä»¥ ç”±äº hugepage ä¼šä¿®æ”¹ page walk ï¼Œæ‰€ä»¥ pud_none å’Œ `__transparent_hugepage_enabled`
  - [ ] æ£€æŸ¥æ›´å¤šçš„ç»†èŠ‚

- [ ] ä» madvise åˆ°å¯åŠ¨ THP
    - [ ] hugepage_vma_check : åˆ°åº•é‚£äº› memory ä¸é€‚åˆ thp
    - [x] `__khugepaged_enter` : å°†æ‰€åœ¨çš„ mm_struct æ”¾åˆ° list ä¸Šï¼Œç­‰å¾…ä¹‹å khugepaged ä¼šå°†è¯¥åŒºåŸŸæ¸…ç†èµ¶ç´§

- [ ] collapse_file : å¤„ç† page cache / shmem / tmpfs
  - [ ] *caller*
      - [ ] khugepaged_scan_file
          - [ ] khugepaged_scan_mm_slot

- [ ] /sys/kernel/mm/transparent_hugepage çš„çœŸæ­£å«ä¹‰ ?
    - [x] khugepaged_enter : è¿™æ˜¯åˆ¤æ–­æ˜¯å¦å°†è¯¥åŒºåŸŸç”¨äº transparent çš„å¼€å§‹ä½ç½®ï¼Œ[Transparent huge pages for filesystems](https://lwn.net/Articles/789159/) ä¸­æ¥çœ‹ï¼Œç°åœ¨æ”¯æŒ THP åªæœ‰ transparent hugepage å’Œ tmp memory äº†
        - [x] do_huge_pmd_anonymous_page : åœ¨ page fault çš„æ—¶å€™ï¼Œä¼šé¦–å…ˆè¿›è¡Œ hugepage æ£€æŸ¥ï¼Œå¦‚æœæ˜¯ always, é‚£ä¹ˆ**æ‰€æœ‰çš„ vma éƒ½ä¼šè¢«è½¬æ¢ä¸º transparent hugepage**
            - [x] create_huge_pmd <= `__handle_mm_fault`

- [ ] ä¸ºä»€ä¹ˆ anonymous çš„ä¸æ”¯æŒ transparet hugepage çš„å•Š?
```c
static vm_fault_t wp_huge_pud(struct vm_fault *vmf, pud_t orig_pud)
{
#if defined(CONFIG_TRANSPARENT_HUGEPAGE) &&			\
	defined(CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE_PUD)
	vm_fault_t ret;

	/* No support for anonymous transparent PUD pages yet */
	if (vma_is_anonymous(vmf->vma))
		goto split;
	if (vmf->vma->vm_flags & (VM_SHARED | VM_MAYSHARE)) {
		if (vmf->vma->vm_ops->huge_fault) {
			ret = vmf->vma->vm_ops->huge_fault(vmf, PE_SIZE_PUD);
			if (!(ret & VM_FAULT_FALLBACK))
				return ret;
		}
	}
split:
	/* COW or write-notify not handled on PUD level: split pud.*/
	__split_huge_pud(vmf->vma, vmf->pud, vmf->address);
#endif /* CONFIG_TRANSPARENT_HUGEPAGE && CONFIG_HAVE_ARCH_TRANSPARENT_HUGEPAGE_PUD */
	return VM_FAULT_FALLBACK;
}
```

å…³é”®é—®é¢˜ B : split_huge_page_to_list

ä¸å…³é”®é—®é¢˜ A : vm_operations_struct::huge_fault å’Œ DAX çš„å…³ç³»ä¸ä¸€èˆ¬
ä¸å…³é”®é—®é¢˜ A2 : vm_operations_struct å‡ ä¹æ²¡æœ‰ä¸€ä¸ªå¯ä»¥ç†è§£çš„


## reference counting
- [ ] total_mapcount

[Transparent huge page reference counting](https://lwn.net/Articles/619738/)

> In particular, he has eliminated the hard separation between normal and huge pages in the system.
> In current kernels, a specific 4KB page can be treated as an individual page,
> or it can be part of a huge page, but not both. If a huge page must be split into individual pages, it is split completely for all users,
> the compound page structure is torn down, and the huge page no longer exists.
> The fundamental change in Kirill's patch set is to allow a huge page to be split in one process's address space, while remaining a huge page in any other address space where it is found.

é¾Ÿé¾Ÿï¼Œsplit page è®©å…±äº«çš„ç‰©ç†é¡µï¼Œåœ¨ä¸€ä¸ªæ˜ å°„ä¸­æ˜¯ hugepageï¼Œåœ¨å¦ä¸€ä¸ªçš„æ˜ å°„ä¸­åˆ†æ•£çš„

```c
/*
 * Mapcount of 0-order page; when compound sub-page, includes
 * compound_mapcount of compound_head of page.
 *
 * Result is undefined for pages which cannot be mapped into userspace.
 * For example SLAB or special types of pages. See function page_has_type().
 * They use this place in struct page differently.
 */
static inline int page_mapcount(struct page *page)
{
	int mapcount = atomic_read(&page->_mapcount) + 1;

	if (likely(!PageCompound(page)))
		return mapcount;
	page = compound_head(page);
	return head_compound_mapcount(page) + mapcount;
}

int total_compound_mapcount(struct page *head);

/**
 * folio_mapcount() - Calculate the number of mappings of this folio.
 * @folio: The folio.
 *
 * A large folio tracks both how many times the entire folio is mapped,
 * and how many times each individual page in the folio is mapped.
 * This function calculates the total number of times the folio is
 * mapped.
 *
 * Return: The number of times this folio is mapped.
 */
static inline int folio_mapcount(struct folio *folio)
{
	if (likely(!folio_test_large(folio)))
		return atomic_read(&folio->_mapcount) + 1;
	return total_compound_mapcount(&folio->page);
}
```

### æ·±å…¥ç†è§£ struct page
```c
		struct {	/* Tail pages of compound page */
			unsigned long compound_head;	/* Bit zero is set */

			/* First tail page only */
			unsigned char compound_dtor;
			unsigned char compound_order;
			atomic_t compound_mapcount;
			atomic_t subpages_mapcount;
			atomic_t compound_pincount;
#ifdef CONFIG_64BIT
			unsigned int compound_nr; /* 1 << compound_order */
#endif
		};
		struct {	/* Second tail page of transparent huge page */
			unsigned long _compound_pad_1;	/* compound_head */
			unsigned long _compound_pad_2;
			/* For both global and memcg */
			struct list_head deferred_list;
		};
		struct {	/* Second tail page of hugetlb page */
			unsigned long _hugetlb_pad_1;	/* compound_head */
			void *hugetlb_subpool;
			void *hugetlb_cgroup;
			void *hugetlb_cgroup_rsvd;
			void *hugetlb_hwpoison;
			/* No more space on 32-bit: use third tail if more */
		};
```

åˆ†æä¸‹ first tail page æ˜¯å¦‚ä½•ä½¿ç”¨çš„:

- prep_compound_page
  - `__SetPageHead`
  - prep_compound_head
  - prep_compound_tail

å‚è€ƒå†…æ ¸æ–‡æ¡£ [Transparent Hugepage Support](http://127.0.0.1:3434/mm/transhuge.html)

> - get_page()/put_page() and GUP operate on head page's ->_refcount.
>
>  - ->_refcount in tail pages is always zero: get_page_unless_zero() never
>    succeeds on tail pages.
>
>  - map/unmap of PMD entry for the whole compound page increment/decrement
>    ->compound_mapcount, stored in the first tail page of the compound page;
>    and also increment/decrement ->subpages_mapcount (also in the first tail)
>    by COMPOUND_MAPPED when compound_mapcount goes from -1 to 0 or 0 to -1.
>
>  - map/unmap of sub-pages with PTE entry increment/decrement ->_mapcount
>    on relevant sub-page of the compound page, and also increment/decrement
>    ->subpages_mapcount, stored in first tail page of the compound page, when
>    _mapcount goes from -1 to 0 or 0 to -1: counting sub-pages mapped by PTE.

- refcount åªæ˜¯ head ç»´æŠ¤
- æ•´ä½“çš„ map count åœ¨ compound_mapcount ä¸­ç»´æŠ¤
- mapcount æ¯ä¸€ä¸ª page éƒ½éœ€è¦ç»´æŠ¤ï¼Œè€Œä¸” subpages æ€»æ•°éœ€è¦åœ¨ subpages_mapcount ä¸­ç»´æŠ¤

#### compound_mapcount
```c
/*
 * If a 16GB hugetlb page were mapped by PTEs of all of its 4kB sub-pages,
 * its subpages_mapcount would be 0x400000: choose the COMPOUND_MAPPED bit
 * above that range, instead of 2*(PMD_SIZE/PAGE_SIZE).  Hugetlb currently
 * leaves subpages_mapcount at 0, but avoid surprise if it participates later.
 */
#define COMPOUND_MAPPED	0x800000
#define SUBPAGES_MAPPED	(COMPOUND_MAPPED - 1)
```
ä¸€ä¸ª COMPOUND_MAPPED è¡¨ç¤ºè¢«æ˜ å°„ä¸ºå¤§é¡µï¼Œè€Œè¢« SUBPAGES_MAPPED ä¸‹çš„ï¼Œè®¡ç®— basepage çš„æ˜ å°„æ¬¡æ•°ã€‚



#### subpages_mapcount

#### compound_dtor
- compound_dtor: å¯ä»¥ç”¨æ¥åŒºåˆ†æ˜¯é‚£ç§ç±»å‹çš„ pageï¼Œä¾‹å¦‚åœ¨ PageHuge

- destroy_large_folio

çœ‹æ¥è¿™ä¸ªæ—¶é—´ä¸Šæ˜¯å­˜åœ¨ä¸‰ä¸ª page çš„ï¼›
```c
compound_page_dtor * const compound_page_dtors[NR_COMPOUND_DTORS] = {
	[NULL_COMPOUND_DTOR] = NULL,
	[COMPOUND_PAGE_DTOR] = free_compound_page,
#ifdef CONFIG_HUGETLB_PAGE
	[HUGETLB_PAGE_DTOR] = free_huge_page,
#endif
#ifdef CONFIG_TRANSPARENT_HUGEPAGE
	[TRANSHUGE_PAGE_DTOR] = free_transhuge_page,
#endif
};
```

è§‚å¯Ÿä¸¤ä¸ª hook çš„ä½¿ç”¨:

-- free_transhuge_page
```txt
@[
    free_transhuge_page+1
    release_pages+491
    tlb_batch_pages_flush+61
    tlb_finish_mmu+101
    unmap_region+218
    do_mas_align_munmap+800
    do_mas_munmap+215
    mmap_region+260
    do_mmap+980
    vm_mmap_pgoff+218
    do_syscall_64+56
    entry_SYSCALL_64_after_hwframe+99
]: 339
```
-- free_compound_page
```txt
@[
    free_compound_page+1
    skb_release_data+202
    consume_skb+57
    unix_stream_read_generic+2326
    unix_stream_recvmsg+136
    ____sys_recvmsg+135
    ___sys_recvmsg+124
    __sys_recvmsg+86
    do_syscall_64+56
    entry_SYSCALL_64_after_hwframe+99
]: 6320
```

```txt
@[
    destroy_large_folio+1
    release_pages+491
    __pagevec_release+27
    shmem_undo_range+692
    shmem_evict_inode+262
    evict+204
    __dentry_kill+223
    __fput+221
    task_work_run+86
    do_exit+835
    do_group_exit+45
    get_signal+2423
    arch_do_signal_or_restart+54
    exit_to_user_mode_prepare+267
    syscall_exit_to_user_mode+23
    do_syscall_64+72
    entry_SYSCALL_64_after_hwframe+99
]: 106
@[
    destroy_large_folio+1
    skb_release_data+202
    consume_skb+57
    unix_stream_read_generic+2326
    unix_stream_recvmsg+136
    ____sys_recvmsg+135
    ___sys_recvmsg+124
    __sys_recvmsg+86
    do_syscall_64+56
    entry_SYSCALL_64_after_hwframe+99
]: 125
```
### åˆ†æä¸‹ compound page

- free_transhuge_page
  - free_compound_page

éªŒè¯ä¸€ä¸ªåŸºæœ¬æƒ³æ³•ï¼Œé‚£å°±æ˜¯ compound_page å°±æ˜¯è¿ç»­çš„å‡ ä¸ªå°é¡µé¢è€Œå·²ã€‚
```txt
$ p page[1].compound_order
$2 = 3 '\003'
$ bt
#0  compound_order (page=0xffffea00048d7600) at ./include/linux/mm.h:721
#1  free_compound_page (page=0xffffea00048d7600) at mm/page_alloc.c:773
#2  0xffffffff81bd827d in folio_put (folio=<optimized out>) at ./include/linux/mm.h:1250
#3  put_page (page=0xffffea00048d7600) at ./include/linux/mm.h:1319
#4  page_to_skb (vi=vi@entry=0xffff8883c1af6900, rq=rq@entry=0xffff888102526000, page=page@entry=0xffffea00048d7600, offset=<optimized out>, len=<optimized out>, len@entry=66, truesize=2048, hdr_valid=true, metasize=0, headroom=0) at drivers/net/virtio_net.c:558
#5  0xffffffff81bdb0a6 in receive_mergeable (stats=0xffffc900022d0e80, xdp_xmit=<optimized out>, len=<optimized out>, ctx=<optimized out>, buf=<optimized out>, rq=0xffff888102526000, vi=0xffff8883c1af6900, dev=0xffff8883c1af6000) at drivers/net/virtio_net.c:1126
#6  receive_buf (vi=0xffff8883c1af6900, rq=0xffff888102526000, buf=<optimized out>, len=<optimized out>, ctx=<optimized out>, xdp_xmit=<optimized out>, stats=0xffffc900022d0e80) at drivers/net/virtio_net.c:1265
#7  0xffffffff81bdc910 in virtnet_receive (xdp_xmit=0xffffc900022d0e70, budget=64, rq=0xffff888102526000) at drivers/net/virtio_net.c:1560
#8  virtnet_poll (napi=0xffff888102526008, budget=<optimized out>) at drivers/net/virtio_net.c:1678
#9  0xffffffff81dd8424 in __napi_poll (n=0xffffea00048d7600, n@entry=0xffff888102526008, repoll=repoll@entry=0xffffc900022d0f37) at net/core/dev.c:6485
#10 0xffffffff81dd8974 in napi_poll (repoll=0xffffc900022d0f48, n=0xffff888102526008) at net/core/dev.c:6552
#11 net_rx_action (h=<optimized out>) at net/core/dev.c:6663
#12 0xffffffff821a0e34 in __do_softirq () at kernel/softirq.c:571
#13 0xffffffff811328ca in invoke_softirq () at kernel/softirq.c:445
#14 __irq_exit_rcu () at kernel/softirq.c:650
#15 0xffffffff8218b8dc in common_interrupt (regs=0xffffc900001d7e38, error_code=<optimized out>) at arch/x86/kernel/irq.c:240
Backtrace stopped: Cannot access memory at address 0xffffc900022d1018
```

#### compound page å¦‚ä½•åˆ›å»ºçš„
ä¸ºä»€ä¹ˆè¿™ä¸ªæ ¹æœ¬æ— æ³•æ‹¦æˆªåˆ°ä»»ä½•ä¸œè¥¿ï¼š
```sh
sudo bpftrace -e 'kfunc:prep_compound_page { @reads[args->order] = count(); }'
```
ä½†æ˜¯åœ¨ QEMU ä¸­é—´æ‰“ç‚¹çš„æ—¶å€™ï¼Œåœ¨è¿™é‡Œæ˜¯å¯ä»¥è·å–åˆ°å¾ˆå¤šå†…å®¹çš„ï¼Œä¹Ÿè®¸æ˜¯ ebpf çš„é—®é¢˜ï¼Œä¹Ÿè®¸å†…æ ¸ç‰ˆæœ¬æœ‰ç‚¹å°åŒºåˆ«ï¼Œä¹Ÿæ˜¯ç¯å¢ƒé…ç½®ä¸åŒã€‚


```sh
sudo bpftrace -e 'kfunc:__alloc_pages { @reads[args->order] = count(); }'
```
å¯ä»¥å¾—åˆ°:
```txt
@reads[2]: 2185
@reads[1]: 3076
@reads[3]: 6123
@reads[0]: 57084
```

sudo bpftrace -e 'kfunc:alloc_pages { if (args->order >= 3) { @[kstack] = count(); } }'

å¯ä»¥å¾—åˆ°å¦‚ä¸‹ä½ç½®ï¼Œ
```tx
@[
    alloc_pages+5
    alloc_skb_with_frags+183
    sock_alloc_send_pskb+569
    unix_stream_sendmsg+487
    sock_sendmsg+95
    __sys_sendto+252
    __x64_sys_sendto+32
    do_syscall_64+56
    entry_SYSCALL_64_after_hwframe+99
]: 2688
```

æ–‡ä»¶ç³»ç»Ÿä¸­çš„ä½¿ç”¨:
- ra_alloc_folio
  - filemap_alloc_folio ä¸­æ˜¯æ–‡ä»¶ç³»ç»Ÿä¹Ÿæ˜¯ä¼šåˆ›å»ºå‡ºæ¥ compound page çš„

alloc_pages_exact æ˜¯åˆ†é…çš„æ—¶å€™ä¸è¦ `__GFP_COMP`ï¼Œå› ä¸ºå…¶éœ€è¦çš„ä¸æ˜¯ 2^^order ä¸ªï¼Œè€Œæ˜¯ç‰¹å®šå¤§å°çš„ï¼Œé¦–å…ˆåˆ†é…ï¼Œç„¶åå°†é¡µé‡Šæ”¾æ‰ã€‚
å› ä¸º compound page åªèƒ½æ˜¯æ˜¯ 2 ^^ order åˆ†é…çš„ã€‚

- [ ] prep_new_page : å¦‚æœæ²¡æœ‰ `__GFP_COMP`ï¼Œæ‰€æœ‰çš„ page çš„ flags æ˜¯å¦‚ä½•åˆå§‹åŒ–çš„?

### åˆ¤æ–­ page ç±»å‹
é‚£ä¹ˆå¦‚ä½•åˆ¤æ–­ä¸€ä¸ª page æ˜¯ä¸æ˜¯ transparent hugepage çš„å“‡ï¼Ÿ
```c
/*
 * PageHuge() only returns true for hugetlbfs pages, but not for normal or
 * transparent huge pages.  See the PageTransHuge() documentation for more
 * details.
 */
int PageHuge(struct page *page)
{
	if (!PageCompound(page))
		return 0;

	page = compound_head(page);
	return page[1].compound_dtor == HUGETLB_PAGE_DTOR;
}
```

å®é™…ä¸Šï¼Œè¿™ä¸ªæµ‹è¯•åªæ˜¯æµ‹è¯• head è€Œå·²ï¼Œä½†æ˜¯é™åˆ¶äº†ä½¿ç”¨èŒƒå›´
```c
static inline bool folio_test_transhuge(struct folio *folio)
{
	return folio_test_head(folio);
}

/*
 * PageHuge() only returns true for hugetlbfs pages, but not for
 * normal or transparent huge pages.
 *
 * PageTransHuge() returns true for both transparent huge and
 * hugetlbfs pages, but not normal pages. PageTransHuge() can only be
 * called only in the core VM paths where hugetlbfs pages can't exist.
 */
static inline int PageTransHuge(struct page *page)
{
	VM_BUG_ON_PAGE(PageTail(page), page);
	return PageHead(page);
}
```

## THP split
è¿™å‡ ä¸ªæ–‡ç« éƒ½æ˜¯è®²è§£ä¸¤ç§æ–¹æ¡ˆï¼Œå¾ˆçƒ¦!
[Transparent huge pages in the page cache](https://lwn.net/Articles/686690/)
> Finally, a file may be used without being mapped into process memory at all, while anonymous memory is always mapped. So any changes to a filesystem to support transparent huge page mapping must not negatively impact normal read/write performance on an unmapped file.

- [x] æ— è®ºæ˜¯åœ¨å†…æ ¸æ€å’Œç”¨æˆ·æ€ä¸­é—´ï¼Œä¸€ä¸ª huge page éƒ½æ˜¯å¯ä»¥éšæ„æ‹†åˆ†çš„ï¼Œåœ¨ç”¨æˆ·æ€æ¯ä¸ªäººéƒ½æ˜¯ä¸åŒçš„æ˜ å°„ã€‚åœ¨å†…æ ¸æ€ï¼Œæ€»æ˜¯çº¿æ€§æ˜ å°„ï¼Œpmd page table entry çš„ä¿®æ”¹å…¶å®æ²¡æœ‰ä»»ä½•æ„ä¹‰ã€‚
- [x] swap cache çš„å®ç°æ ¹æœ¬æŒ‘æˆ˜åœ¨äºåŒºé—´çš„å¯ä»¥éšæ„å˜åŒ–

[Improving huge page handling](https://lwn.net/Articles/636162/)

[Transparent huge page reference counting](https://lwn.net/Articles/619738/)
> In many other situations, Andrea placed a call to split_huge_page(), a function which breaks a huge page down into its component small pages.

> In other words, if split_huge_page() could be replaced by a new function, call it split_huge_pmd(), that would only split up a single process's mapping of a huge page, code needing to deal with individual pages could often be accommodated while preserving the benefits of the huge page for other processes. But, as noted above, the kernel currently does not support different mappings of huge pages; all processes must map the memory in the same way. This restriction comes down to how various parameters â€” reference counts in particular â€” are represented in huge pages.

> it must be replaced by a scheme that can track both the mappings to the huge page as a whole and the individual pages that make up that huge page.


```c
#define split_huge_pmd(__vma, __pmd, __address)       \
  do {                \
    pmd_t *____pmd = (__pmd);       \
    if (is_swap_pmd(*____pmd) || pmd_trans_huge(*____pmd) \
          || pmd_devmap(*____pmd))  \
      __split_huge_pmd(__vma, __pmd, __address, \
            false, NULL);   \
  }  while (0)
```

- [ ] split_huge_page_to_list
  - [ ] `__split_huge_page` : ä¸å¯¹åŠ²ï¼Œä¼¼ä¹ hugepage åªæ˜¯ä½“ç°åœ¨ struct page ä¸Šï¼Œè€Œæ²¡æœ‰ä½“ç°åœ¨ pmd ä¸Š
      - [x] åœ¨ huge page ä¸­é—´æ‹†åˆ†å‡ºæ¥å‡ ä¸ªå½“åšå…¶ä»–çš„ page æ­£å¸¸ä½¿ç”¨, è™½ç„¶ä»ä¸­é—´æŠ å‡ºæ¥çš„é¡µé¢ä¸å¯ä»¥ç»§ç»­å½“åšå†…æ ¸ï¼Œä½†æ˜¯å¯ä»¥ç»™ç”¨æˆ·ä½¿ç”¨
          - [ ] æ˜¯å¦å­˜åœ¨ flag è¯´æ˜é‚£äº›é¡µé¢å¯ä»¥åˆ†é…ç»™ç”¨æˆ·ï¼Œé‚£äº›æ˜¯å†…æ ¸ ?

- [ ] `__split_huge_pmd` : å¤„ç†å„ç§ lock åŒ…æ‹¬ pmd_lock
  - [ ] `__split_huge_pmd_locked`
    - å–å› pmd_huge_pteï¼Œå‘å…¶ä¸­å¡«å…… pte, ç„¶åå°† pmd entry å¡«å……è¯¥ä½ç½®
  - `pgtable_t page::(anonymous union)::(anonymous struct)::pmd_huge_pte`
      - [ ]  ä» `__split_huge_pmd_locked` çš„ä»£ç : `pgtable_trans_huge_withdraw` çœ‹ï¼Œè¿™ä¸€ä¸ª page table ä»æ¥æ²¡æœ‰è¢«åˆ é™¤è¿‡

## zero page
By default kernel tries to use huge zero page on read page fault to anonymous mapping. Itâ€™s possible to disable huge zero page by writing 0 or enable it back by writing 1:

Contrary to the zero page's original preferential use,
some modern operating systems such as FreeBSD, Linux and Microsoft Windows[2] actually make the zero page inaccessible to trap uses of null pointers.

## transhuge å¯¹äºå…¶ä»–æ¨¡å—çš„æ”¯æŒ

### copy page
1. copy_huge_pmd
2. copy_huge_pud

dup_mmap ä¸­é—´é€çº§ä¸‹æ²‰ä¸‹æ¥çš„

### page fault

```txt
#0  __do_huge_pmd_anonymous_page (gfp=<optimized out>, page=<optimized out>, vmf=<optimized out>) at mm/huge_memory.c:837
#1  do_huge_pmd_anonymous_page (vmf=vmf@entry=0xffffc900017afdf8) at mm/huge_memory.c:837
#2  0xffffffff812dcec8 in create_huge_pmd (vmf=0xffffc900017afdf8) at mm/memory.c:4820
#3  __handle_mm_fault (vma=vma@entry=0xffff888125587da8, address=address@entry=140581166645248, flags=flags@entry=597) at mm/memory.c:5067
#4  0xffffffff812dd680 in handle_mm_fault (vma=0xffff888125587da8, address=address@entry=140581166645248, flags=flags@entry=597, regs=regs@entry=0xffffc900017aff58) at mm/memory.c:5218
#5  0xffffffff810f3ca3 in do_user_addr_fault (regs=regs@entry=0xffffc900017aff58, error_code=error_code@entry=6, address=address@entry=140581166645248) at arch/x86/mm/fault.c:1428
#6  0xffffffff81fa8f72 in handle_page_fault (address=140581166645248, error_code=6, regs=0xffffc900017aff58) at arch/x86/mm/fault.c:1519
#7  exc_page_fault (regs=0xffffc900017aff58, error_code=6) at arch/x86/mm/fault.c:1575
#8  0xffffffff82000b62 in asm_exc_page_fault () at ./arch/x86/include/asm/idtentry.h:570
```

- `__handle_mm_fault`
  - do_huge_pmd_anonymous_page
    - transhuge_vma_suitable : æ£€æŸ¥æ˜¯å¦ vma ä¸­é—´æ˜¯å¦å¯ä»¥å®¹çº³ hugepage
    - å‡å¦‚å¯ä»¥ä½¿ç”¨ zero page æœºåˆ¶
    - vma_thp_gfp_mask : æ ¹æ® vma è·å– gfp
    - vma_alloc_folio : åˆ†é… page
      - `__do_huge_pmd_anonymous_page` : å°†åˆ†é…çš„ page å’Œ page table ç»„è£…
  - vmf->vma->vm_ops->huge_fault : æ–‡ä»¶æ˜ å°„ï¼Œå¦‚æœæ–‡ä»¶ç³»ç»Ÿæ³¨å†Œäº†

## prep_transhuge_page åˆ†é… thp ä¹‹åçš„å‡†å¤‡

- `__folio_alloc` ä¸€å®šæ˜¯åˆ†é… hugepage

```sh
sudo bpftrace -e 'kfunc:__folio_alloc { if (args->order > 1) { @reads[kstack] = count(); }}'
```

å¾—åˆ°å¦‚ä¸‹å†…å®¹:
```txt
@reads[
    __folio_alloc+5
    vma_alloc_folio+663
    do_huge_pmd_anonymous_page+179
    __handle_mm_fault+2322
    handle_mm_fault+178
    do_user_addr_fault+460
    exc_page_fault+103
    asm_exc_page_fault+34
]: 3
@reads[
    __folio_alloc+5
    vma_alloc_folio+663
    shmem_alloc_hugefolio+199
    shmem_alloc_and_acct_folio+169
    shmem_get_folio_gfp+499
    shmem_read_mapping_page_gfp+75
    shmem_sg_alloc_table+364
    shmem_get_pages+182
    __i915_gem_object_get_pages+56
    i915_gem_set_domain_ioctl+616
    drm_ioctl_kernel+178
    drm_ioctl+479
    __x64_sys_ioctl+135
    do_syscall_64+56
    entry_SYSCALL_64_after_hwframe+99
]: 196
```

## anonymous å’Œ shared éƒ½æ˜¯å¦‚ä½•åˆå§‹åŒ–çš„

## ShmemHugePages åœ¨æˆ‘çš„ä¸ªäººæœºå™¨ä¸Šæ€»æ˜¯ä¸ä¸º 0

è®¾ç½®å‚æ•°ä¸º transparent_hugepage=neverï¼Œä½†æ˜¯ç»“æœä¸ºï¼š

```txt
AnonHugePages:         0 kB
ShmemHugePages:   845824 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
```

æ£€æŸ¥é‚£äº›è¿›ç¨‹åœ¨ä½¿ç”¨å¤§é¡µ:
```sh
sudo grep -e AnonHugePages  /proc/*/smaps | awk  '{ if($2>4) print $0} ' |  awk -F "/"  '{print $0; system("ps -fp " $3)} '
```

```sh
sudo grep -e ShmemHugePages /proc/*/smaps | awk  '{ if($2>4) print $0} ' |  awk -F "/"  '{print $0; system("ps -fp " $3)} '
```

æ£€æŸ¥ä¸åˆ°ä»»ä½•è¿›ç¨‹ä½¿ç”¨è¿‡ thpï¼Œä½†æ˜¯
- shmem_add_to_page_cache
  - æ£€æŸ¥ cat /proc/vmstat å‘ç°æœ‰å¾ˆå¤š

æ‰€ä»¥ï¼Œåº”è¯¥æ˜¯æ˜¾å¡é©±åŠ¨çš„é—®é¢˜:
```txt
@[
    shmem_add_to_page_cache+1
    shmem_get_folio_gfp+580
    shmem_read_mapping_page_gfp+75
    shmem_sg_alloc_table+364
    shmem_get_pages+182
    __i915_gem_object_get_pages+56
    i915_gem_set_domain_ioctl+616
    drm_ioctl_kernel+178
    drm_ioctl+479
    __x64_sys_ioctl+135
    do_syscall_64+56
    entry_SYSCALL_64_after_hwframe+99
]: 64977
```

## Transparent hugepage æ˜¯å¦‚ä½•è¿›è¡Œ lru çš„

æ²¡æœ‰ä»€ä¹ˆç‰¹æ®Šå¤„ç†ï¼Œå°±æ˜¯å½“ä½œä¸€ä¸ª page äº†

## split_huge_page_to_list

transparet hugeapge ä¼šå› ä¸º memory pressure è€Œè¢«æ‹†åˆ†å—?

ä¼šçš„ï¼Œåœ¨ shrink_folio_list ä¸­ï¼Œåªè¦å‘ç°ä¸€ä¸ª transparent hugepage æ˜¯ inactive çš„ï¼Œé‚£ä¹ˆé¦–å…ˆå°±ä¼šè¿›è¡Œæ‹†åˆ†ï¼Œè¿›è€Œå°±åƒæ˜¯æ™®é€šé¡µä¸€æ ·è¢« swap çš„
```txt
#0  __split_huge_pmd_locked (freeze=<optimized out>, haddr=<optimized out>, pmd=<optimized out>, vma=<optimized out>) at mm/huge_memory.c:2308
#1  __split_huge_pmd (vma=vma@entry=0xffff8883dd144260, pmd=0xffff8883588cb210, address=address@entry=139950574010368, freeze=true, folio=folio@entry=0xffffea000de68000) at mm/huge_memory.c:2308
#2  0xffffffff8138f4dd in split_huge_pmd_address (vma=vma@entry=0xffff8883dd144260, address=address@entry=139950574010368, freeze=freeze@entry=true, folio=folio@entry=0xffffea000de68000) at mm/huge_memory.c:2337
#3  0xffffffff813418c0 in try_to_migrate_one (folio=0xffffea000de68000, vma=0xffff8883dd144260, address=139950574010368, arg=<optimized out>) at mm/rmap.c:1858
#4  0xffffffff8133ebe3 in rmap_walk_anon (folio=folio@entry=0xffffea000de68000, rwc=rwc@entry=0xffffc90003d63a00, locked=locked@entry=true) at mm/rmap.c:2443
#5  0xffffffff81341b66 in rmap_walk_locked (rwc=0xffffc90003d63a00, folio=0xffffea000de68000) at mm/rmap.c:2530
#6  try_to_migrate (folio=folio@entry=0xffffea000de68000, flags=flags@entry=(TTU_SPLIT_HUGE_PMD | TTU_SYNC | TTU_RMAP_LOCKED)) at mm/rmap.c:2173
#7  0xffffffff8138faa8 in unmap_folio (folio=<optimized out>) at mm/huge_memory.c:2388
#8  split_huge_page_to_list (page=page@entry=0xffffea000de68000, list=list@entry=0xffffc90003d63c30) at mm/huge_memory.c:2741
#9  0xffffffff812f8f5a in split_folio_to_list (list=0xffffc90003d63c30, folio=0xffffea000de68000) at ./include/linux/huge_mm.h:444
#10 shrink_folio_list (folio_list=folio_list@entry=0xffffc90003d63c30, pgdat=pgdat@entry=0xffff8883bfffc000, sc=sc@entry=0xffffc90003d63dd8, stat=stat@entry=0xffffc90003d63cb8, ignore_references=ignore_references@entry=false) at mm/vmscan.c:1856
#11 0xffffffff812fa884 in shrink_inactive_list (lru=LRU_INACTIVE_ANON, sc=0xffffc90003d63dd8, lruvec=0xffff88835698e800, nr_to_scan=<optimized out>) at mm/vmscan.c:2526
#12 shrink_list (sc=0xffffc90003d63dd8, lruvec=0xffff88835698e800, nr_to_scan=<optimized out>, lru=LRU_INACTIVE_ANON) at mm/vmscan.c:2767
#13 shrink_lruvec (lruvec=lruvec@entry=0xffff88835698e800, sc=sc@entry=0xffffc90003d63dd8) at mm/vmscan.c:5951
#14 0xffffffff812fb14e in shrink_node_memcgs (sc=0xffffc90003d63dd8, pgdat=0xffff8883bfffc000) at mm/vmscan.c:6138
#15 shrink_node (pgdat=pgdat@entry=0xffff8883bfffc000, sc=sc@entry=0xffffc90003d63dd8) at mm/vmscan.c:6169
#16 0xffffffff812fb897 in kswapd_shrink_node (sc=0xffffc90003d63dd8, pgdat=0xffff8883bfffc000) at mm/vmscan.c:6960
#17 balance_pgdat (pgdat=pgdat@entry=0xffff8883bfffc000, order=order@entry=0, highest_zoneidx=highest_zoneidx@entry=3) at mm/vmscan.c:7150
#18 0xffffffff812fbe6f in kswapd (p=0xffff8883bfffc000) at mm/vmscan.c:7410
#19 0xffffffff811556a4 in kthread (_create=0xffff8883c18e01c0) at kernel/kthread.c:376
#20 0xffffffff81002659 in ret_from_fork () at arch/x86/entry/entry_64.S:308
```

## [ ] ä¸ºä»€ä¹ˆ transparent hugepage ä¼šè®© idle page tracking ä¸å‡†

## [ ] åˆ°åº•æ˜¯ä½¿ç”¨ pmd è¿˜æ˜¯ä½¿ç”¨ pud çš„

## MADV_COLLAPSE
commit å†™çš„å¾ˆè¯¦ç»†çš„äº†ï¼›
- 7d8faaf155454f8798ec56404faca29a82689c77
- https://lwn.net/Articles/887753/
7d8faaf155454f8798ec56404faca29a82689c77

## çœ‹çœ‹ä¸ºä»€ä¹ˆæ•°æ®åº“ä¸å–œæ¬¢
- https://www.mongodb.com/docs/manual/tutorial/transparent-huge-pages/
- https://www.pingcap.com/blog/transparent-huge-pages-why-we-disable-it-for-databases/

## [ ] è¿™äº›æ“ä½œéœ€è¦è§£å†³æ‰

```txt
AnonHugePages:   3448832 kB
ShmemHugePages:  2045952 kB
ShmemPmdMapped:        0 kB
FileHugePages:         0 kB
FilePmdMapped:         0 kB
```

ç›®å‰åªæœ‰ç¬¬ä¸€ä¸ªæˆåŠŸçš„å®ç°çš„è°ƒæ•´è¿‡ï¼Œå…¶ä»–çš„ä¸å—æ§åˆ¶ã€‚

ä½¿ç”¨è¿™ç§å¯ä»¥å¢åŠ : AnonHugePages
```c
  void *ptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
```

ä½†æ˜¯ä½¿ç”¨è¿™ä¸ªä¸ä¼šå¢åŠ ä»»ä½•æ•°å€¼:
```c
  void *ptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_SHARED, -1, 0);
```

ä½¿ç”¨ QEMU æµ‹è¯• share=off ä¹Ÿæ˜¯ç±»ä¼¼çš„æ•ˆæœ

ä½†æ˜¯ shmem_enabled ä¹‹å
```txt
ğŸ§€  cat /sys/kernel/mm/transparent_hugepage/shmem_enabled
always within_size advise [never] deny force
```

è¿™ä¸¤ä¸ªéƒ½å¯ä»¥å‘ç”Ÿå˜åŒ–

```txt
ShmemHugePages:  2998272 kB
ShmemPmdMapped:   862208 kB
```

æ˜ å°„æ–‡ä»¶æ€»æ˜¯å¤±è´¥.

ä¼¼ä¹æœ‰ç‚¹éš¾è§¦å‘ã€‚

## page cache
æ ¹æœ¬æ²¡åŠæ³•è®©å…¶ä¸ä¸º 0

```txt
FileHugePages:         0 kB
FilePmdMapped:         0 kB
```

å­˜åœ¨ä¸¤ä¸ªä½ç½®:
- filemap_unaccount_folio : åˆ é™¤çš„æ—¶å€™
- `__filemap_add_folio`
  - å…¶è°ƒç”¨ä½ç½®ä¸º : filemap_add_folio hugetlb_add_to_page_cache

- filemap_add_folio çš„è°ƒç”¨ä½ç½®åœ¨ filemap.c å’Œ readahead.c ä½†æ˜¯é€šè¿‡è°ƒç”¨ **filemap_alloc_folio** åˆ›å»º folio ï¼Œå½“ folio çš„ order è¶…è¿‡ HPAGE_PMD_ORDER ï¼Œé‚£ä¹ˆå°±è®¤ä¸ºæ˜¯
å¤§é¡µäº†ã€‚

ä½†æ˜¯ï¼Œfio ä»¥åŠ ccls index æ˜¾ç¤ºå…¨éƒ¨éƒ½æ˜¯ order = 1
```txt
ğŸ§€  sudo bpftrace -e "kfunc:filemap_alloc_folio { @order = lhist(args->order, 0, 100, 1); }"

Attaching 1 probe...
^C

@order:
[0, 1)            136239 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
```

æ¢è¨€ä¹‹ï¼Œè¿™ä¸ªè¿‡ç¨‹æ ¹æœ¬æ— æ³•è§¦å‘:
```sh
sudo bpftrace -e "kfunc:filemap_alloc_folio { if (args->order > 0) { print(\"good\") } }"
```

é€šè¿‡ä¸æ–­çš„æŸ¥æ‰¾ filemap_alloc_folio çš„ reference ï¼Œæœ€åå¯ä»¥æ‰¾åˆ°:
- filemap_fault ä¸­ï¼Œæ‰€åœ¨çš„ vma è¢« madvise äº† MADV_HUGEPAGEï¼Œé‚£ä¹ˆå°±ä¼šä½¿ç”¨å¤§é¡µ

```c
#include <errno.h>
#include <stdio.h>
#include <string.h>
#include <sys/mman.h>
#include <unistd.h>
#include <fcntl.h>
#include <stdlib.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>

const unsigned long PAGE_SIZE = 4 * 1024;
unsigned long MAP_SIZE = 4000L * 1024 * 1024;

int get_file() {
  int fd = open("/root/huge", O_RDWR | O_CREAT, 0644);
  if (fd == -1)
    goto err;

  if (ftruncate(fd, MAP_SIZE) < 0)
    goto err;
  return fd;
err:
  printf("%s\n", strerror(errno));
  exit(1);
}

int main() {
  void *ptr =
      mmap(NULL, MAP_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, get_file(), 0);
  if (ptr == MAP_FAILED)
    goto err;

  if (madvise(ptr, MAP_SIZE, MADV_HUGEPAGE) == -1)
    goto err;

  char m = '1';
  for (unsigned long i = 0; i < MAP_SIZE; i += PAGE_SIZE) {
    m += *((char *)(ptr + i));
  }
  return 0;

err:
  printf("munmap failed: %s\n", strerror(errno));
  return 1;
}
```

é€šè¿‡è¿™ä¸ªæµ‹è¯•ï¼Œçš„ç¡®å¯ä»¥èµ°åˆ° do_sync_mmap_readaheadï¼Œä½†æ˜¯æ•°å€¼è¿˜æ˜¯æ²¡æœ‰å˜åŒ–ã€‚
æœ€åï¼Œæ£€æŸ¥ä¸€ä¸‹ï¼Œå‘ç° ext4 æ ¹æœ¬ä¸æ”¯æŒï¼Œéœ€è¦ä½¿ç”¨ xfs

ä¿®æ”¹ä¹‹åï¼Œå¾—åˆ°å¦‚ä¸‹å†…å®¹:
```txt
AnonHugePages:     20480 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
FileHugePages:   4096000 kB
FilePmdMapped:   4096000 kB
```

## [ ] å¦‚æœ order = 3 è¿™ç§å’Œæ–‡ä»¶ç³»ç»Ÿæ²Ÿé€šçš„ folio æš‚æ—¶ä¸çŸ¥é“å¦‚ä½•åˆ†é…çš„

# 13 Concurrent Hashing and Natural Parallelism

## 13.1 Introduction
In some hash-based set algorithms, each table entry refers to a single item, an
approach known as `open addressing`. In others, each table entry refers to a set of
items, traditionally called a bucket, an approach known as `closed addressing`.

In both kinds of algorithms, it is sometimes necessary to
resize the table. In open-addressing algorithms, the table may become too full to
find alternative table entries, and in closed-addressing algorithms, buckets may
become too large to search efficiently

## 13.2 Closed-Address Hash Set
Later, we look at three alternative synchronization techniques:
1. one using a single coarse-grained lock,
2. one using a fixed-size array of locks, and
3. one using a resizable array of locks

We still need to decide when to resize the hash set, and how the resize()
method synchronizes with the others. There are many reasonable alternatives.
For closed-addressing algorithms, one simple strategy is to resize the set when
the average bucket size exceeds a fixed threshold. An alternative policy employs
two fixed integer quantities: the bucket threshold and the global threshold

- If more than, say, 1/4 of the buckets exceed the bucket threshold, then double
the table capacity, or
- If any single bucket exceeds the global threshold, then double the table
capacity


#### 13.2.1 A Coarse-Grained Hash Set
> 介绍一个正常人认可的锁
> 但是利用的lock 是ReentrantLock()，

#### 13.2.2 A Striped Hash Set
> 将table分区管理

Because the `initializeFrom()` method calls `add()`, it may
trigger nested calls to resize(). We leave it as an exercise to check that nested
resizing works correctly in this and later hash set implementations
> 我有点怀疑这本书的错误有点多，显然本section 从来没有介绍过任何 `initializeFrom`

#### 13.2.3 A Refinable Hash Set
Resizing is rare, so our principal goal is to devise a way to permit
the lock array to be resized without substantially increasing the cost of normal
method calls.

We use the `owner` as a mutual exclusion flag between the resize() method and any of the add() methods.

acquire() 是其add update的lock，而 resize 并不会使用。

```java
/**
   * Synchronize before adding, removing, or testing for item
   * @param x item involved
   */
  public void acquire(T x) {
    boolean[] mark = {true};
    Thread me = Thread.currentThread();
    Thread who;
    while (true) {
      do { // wait until not resizing
        who = owner.get(mark);
      } while (mark[0] && who != me);
      // 所以，必须保证其他的thread 没有在resize
      // 那么，当自己resize 没有问题 ? 除非在resize的时候需要 acquire ?

      ReentrantLock[] oldLocks = this.locks;
      int myBucket = Math.abs(x.hashCode() % oldLocks.length);
      ReentrantLock oldLock = oldLocks[myBucket];
      oldLock.lock();  // acquire lock
      who = owner.get(mark);
      if ((!mark[0] || who == me) && this.locks == oldLocks) { // recheck
        // 因为当前的机制中间，利用owner 其实不是正常的lock 并没有达到的形成lock 的作用，不能保证其中正在进行resize
        // 说明 :
        // 1. 当前lock 没有被注销，必须满足
        // 3. !(mark[0] && who !=me) 的情况，被展开了而已，实现的内容。

        // 条件刚刚通过的时候，此时进行resize ?
        return;
      } else {  //  unlock & try again
        oldLock.unlock();
      }
    }
  }
  // 当已经 acquire 到lock 进行添加的时候，然后 sleep, 此时如何保证 resize 无法进入 ?
  // resize 会被阻塞到 通过 quiesce。

  /**
   * double the set size
   */
  public void resize() {
    int oldCapacity = table.length;
    int newCapacity = 2 * oldCapacity;
    Thread me = Thread.currentThread();
    // 只要当前含有进程在resize 那么可以保证 true thread_id
    if (owner.compareAndSet(null, me, false, true)) {
      try {
        // 为什么需要检查 ?
        // 因为, A 执行前面3句话，B 执行完成所有的内容，A 再进行执行的时候，
        // 其实resize 的工作已经完成了，但是其实没有必要继续了 !
        // TODO 这个地方就非常傻逼了，所以为什么直接将 　
        /* int oldCapacity = table.length; */
        /* int newCapacity = 2 * oldCapacity; */
        // 放到lock 里面来 !
        if (table.length != oldCapacity) {  // someone else resized first
          return;
        }

        // 需要等到所有lock释放!
        // 难道不是互斥的 ?
        // 只会进一步的阻止resize 但是正在进行的需要等待 !
        quiesce();
        List<T>[] oldTable = table;
        table = (List<T>[]) new List[newCapacity];
        for (int i = 0; i < newCapacity; i++)
          table[i] = new ArrayList<T>();
        locks = new ReentrantLock[newCapacity];
        for (int j = 0; j < locks.length; j++) {
          locks[j] = new ReentrantLock();
        }
        initializeFrom(oldTable);
      } finally {
        owner.set(null, false);       // restore prior state
      }
    }
  }

  // 当前在进行，release的时候，在进行resize() ?
  // 因为如果当前release需要进行，　说明存在某个线程持有lock，那么resize 无法进行
  public void release(T x) {
    int myBucket = Math.abs(x.hashCode() % locks.length);
    locks[myBucket].unlock();
  }
```

The `acquire()` and the `resize()` methods guarantee mutually exclusive access
via the flag principle using the mark field of the owner flag and the table’s locks
array: `acquire()` first acquires its locks and then reads the mark field, while
`resize()` first sets mark and then reads the locks during the `quiesce()` call.
This　ordering ensures that any thread that acquires the locks after `quiesce()` has completed
will see that the set is in the processes of being resized, and will back off
until the resizing is complete. Similarly, `resize()` will first set the mark field, then
read the locks, and will not proceed while any `add()`, `remove()`, or `contains()`
call’s lock is set

Because the initializeFrom() method calls add(), it may trigger nested calls to resize().

> 虽然问题有些小毛病，但是，但是其设计思路感觉难以模仿，so，what is the paradiam ?

## 13.3 A Lock-Free Hash Set
> 进入不当人阶段

The next step is to make the hash set implementation lock-free, and to make
resizing incremental, meaning that each add() method call performs a small `fraction` of the work associated with resizing.

*To make resizable hashing lock-free, it is not enough to make the individual
buckets lock-free*, because resizing the table requires atomically moving entries
from old buckets to new buckets. If the table doubles in capacity, then we must
split the items in the old bucket between two new buckets. If this move is not
done atomically, entries might be temporarily lost or duplicated.


#### 13.3.1 Recursive Split-Orderi

More specifically, keep all items in a single lock-free linked list, similar to the
`LockFreeList` class studied in Chapter 9. A bucket is just a reference into the
list.

As the list grows, we introduce additional bucket references so that no object
is ever too far from the start of a bucket. This algorithm ensures that once an item
is placed in the list, it is never moved, but it does require that items be inserted
according to a *recursive split-order* algorithm that we describe shortly
> ??? recursive split-order 是什么东西 ?

Here, however, the table is resized incrementally by the methods that modify it, so there
is no explicit `resize()` method.

Because the hash function depends on the table capacity, we must be careful
when the table capacity changes. An item inserted before the table was resized
must be accessible afterwards from both its previous and current buckets.

Here is the key idea behind the algorithm:
we ensure that these two groups of items are positioned one after the
other in the list, so that splitting bucket b is achieved by simply setting bucket
`b + 2^i` after the first group of items and before the second.
This organization keeps each item in the second group accessible from bucket `b`.
> hash数值的计算和size无关，但是，object放置的位置是和所在的空间相关的.

To avoid an awkward “corner case” that arises when deleting a node referenced
by a bucket reference, we add a sentinel node, which is never deleted, to the start
of each bucket.
> 被bucket reference的node永远都不会被删除
> ? 被删除了, 需要将 bucket 的 reference 设置为 null 而已吧
> 所以哨兵需要具有什么特性: 用于在该bucket(设置需要为b)的第一个
> ? 扩张的过程 : 整个bucket倍增


two methods: makeOrdinaryKey(), which generates a split-ordered
key for an object, and makeSentinelKey(), which generates a split-ordered key
for a bucket index
> sentinel 节点的处理的corner case 是 : To avoid an awkward “corner case” that arises when deleting a node referenced by a bucket reference, we add a sentinel node, which is never deleted, to the start of each bucket
> bucket 的 reference 不应该被删除，否则 ?

To keep the example concrete, we implement the following policy: we use a shared counter to allow
`add()` calls to track the average bucket load. When the average load crosses a
threshold, we double the table capacity.

To avoid technical distractions, we keep the array of buckets in a large,
fixed-size array. We start out using only the first array entry, and use progressively more of the array as the set grows.
When the add() method accesses an uninitialized bucket that should have been initialized given the current table
capacity, it initializes it. While conceptually simple, this design is far from ideal,
since the fixed array size limits the ultimate number of buckets. In practice, it
would be better to represent the buckets as a multilevel tree structure which
would cover the machine’s full memory size, a task we leave as an exercise
> 毕竟每一个bucket 都含有自己的parent


#### 13.3.2 The BucketList Class

#### 13.3.3 The LockFreeHashSet<T> Class

## 13.4 An Open-Addressed Hash Set

#### 13.4.1 Cuckoo Hashing
> 同一个object 只能出现在两个位置，也就是
> 在左侧的相同位置的不仅仅可以出现在同一个位置

#### 13.4.2 Concurrent Cuckoo Hashing
The principal obstacle to making the sequential Cuckoo hashing algorithm
concurrent is the `add()` method’s need to perform a long sequence of swaps.
To address this problem, we now define an alternative Cuckoo hashing algorithm, the `PhasedCuckooHashSet<T>` class
We break up each method call into a
sequence of phases, where each phase adds, removes, or displaces a single item x.

Rather than organizing the set as a two-dimensional table of items, we use
a two-dimensional table of *probe sets*, where a probe set is a constant-sized set
of items with the same hash code.

Each probe set holds at most `PROBE_SIZE`
items, but the algorithm tries to ensure that when the set is quiescent (i.e., no
method calls are in progress) each probe set holds no more than `THRESHOLD`
< `PROBE_SIZE` items.

From a bird’s eye view, the `PhasedCuckooHashSet<T>` works as follows.
It adds and removes items by first locking the associated probe sets in both tables

To *remove* an item, it proceeds as in the sequential algorithm, checking if it is
in one of the probe sets and removing it if so. To *add* an item, it attempts to
add it to one of the probe sets. An item’s probe sets serves as temporary overflow
buffer for *long sequences of consecutive displacements* that might occur
when adding an item to the table.

The algorithm then tries to relocate another item from the probe set.

There are various policies one can use to choose which item to relocate. Here, we move
the oldest items out first, until the probe set is below threshold.
*As in the sequential cuckoo hashing algorithm, one relocation may trigger another, and so on.*

The relocate() method takes the row and column
coordinates of a probe set observed to have more than THRESHOLD items, and
tries to reduce its size below threshold by moving items from *this probe set* to *alternative probe set*.

Each time around the loop, the following invariants hold: iSet is the probe set we are
trying to shrink, y is the oldest item in iSet, and jSet is the other probe set where y could be.

> 分析一下 relocate

#### 13.4.3 Striped Concurrent Cuckoo Hashing
The StripedCuckooHashSet class extends
PhasedCuckooHashSet, providing a fixed 2-by-L array of reentrant locks
As usual, `lock[i][j]` protects `table[i][k]`, where k (mod L) = j

The StripedCuckooHashSet class’s acquire(x) method locks `lock[0][h0(x)]` and `lock[1][h1(x)]` in that order,
to avoid deadlock. The release(x) method unlocks those locks.
> ? 所以可以构造一个可以造成lock 的情况吗 ?
> 可能只是为了配合resize 使用

The only difference between the resize() methods of `StripedCuckooHashSet`
and StripedHashSet is that the latter acquires the locks in `lock[0]`
in ascending order
> 简单的移动，但是要逐个对于整个table 上锁
> 上一个版本resize 没有实现啊 !

#### 13.4.4 A Refinable Concurrent Cuckoo Hash Set
Just as for the RefinableHashSet class, we introduce an owner field of type
AtomicMarkableReference<Thread> that combines a Boolean value with a
reference to a thread. If the Boolean value is true, the set is resizing, and the
reference indicates which thread is in charge of resizing.
> 不在使用lock 而是采用 refinable 的内容，将其中resize 和 add 等操作使用 owner 进行控制

## 问题
https://tessil.github.io/2016/08/29/hopscotch-hashing.html

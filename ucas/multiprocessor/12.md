# Counting, sorting and distributed Coordination

## 12.1 Introduction
In Chapter 11 we saw how to apply distributed coordination to the `EliminationBackoffStack` class.

Here, we cover several useful patterns for distributed coordination: *combining*, *counting*, *diffraction*, and *sampling*.
*Some are deterministic, while others use randomization*. We also cover two basic structures underlying these patterns: trees and combinatorial networks.
Interestingly, for some data structures based on distributed coordination, high throughput
does not necessarily mean low latency.
> review later ?

## 12.2 Shared Counting
We now explore the idea that **shared counters need not be bottlenecks**, and can be effectively parallelized. We face two challenges.
1. We must avoid memory contention, where too many threads try to access the
same memory location, stressing the underlying communication network and
cache coherence protocols.
2. We must achieve real parallelism. Is incrementing a counter an inherently
sequential operation, or is it possible for n threads to increment a counter
faster than it takes one thread to increment a counter n times?

## 12.3 Software Combining
A `CombiningTree` is a binary tree of nodes, where each node contains
bookkeeping information. The counter’s value is stored at the root. Each thread
is assigned a leaf, and at most two threads share a leaf, so if there are p physical
processors, then there are p/2 leaves.
> leaf node shared by 2 node !

One thread, the active thread, propagates their combined increments up the tree, while the other, the passive thread, waits for the active thread to
complete their combined work. A thread may be active at one level and become
passive at a higher level.
> 累加向上合并，但是同一棵树上存在多个counter 在向上，为什么需要区分 ? 如果不区分，counter 会成为什么 ?
> passive 的等待的含义是什么 ?

For example, using a queue lock, p getAndIncrement()
calls complete in O(p) time, at best, while using a CombiningTree, under ideal
conditions where all threads move up the tree together, p getAndIncrement()
calls complete in O(log p) time, an exponential improvement.
> 1. 这样实现的 getAndIncrement 可以用来实现"atomic queue" 吗 ?
> 2. 如果passive 的等待，的确含有 wait 操作 ?

Still, the CombiningTree class, like other techniques we consider later, is
intended to benefit throughput, not latency.


#### 12.3.1 Overview
we split the data structure into two classes: the *CombiningTree*
class manages navigation within the tree, moving up and down the tree as
needed, while the *Node* class manages each visit to a node

*The algorithm also requires excluding threads from a node for durations longer than a single method call*. Such
long-term synchronization is provided by a *Boolean locked* field. When this
field is true, no other thread is allowed to access the node.

Every tree node has a combining status, which defines whether the node is in
the early, middle, or late stages of combining concurrent requests

These values have the following meanings:
- `IDLE`: This node is not in use.
- `FIRST`: One active thread has visited this node, and *will return to check
whether another passive thread has left a value with which to combine*.
> active 先到达，然后等待是否存在其他的节点来combine，如果一直都没有，何如?
- `SECOND`: A second thread has visited this node and stored a value in the node’s
value field to be combined with the active thread’s value, but the combined
operation is not yet complete
> combined 了，但是 combined operation 尚未完成 ?
- `RESULT`: Both threads’ operations have been *combined* and *completed*, and
*the second thread’s result has been stored in the node’s result field*.
- `ROOT`: This value is a special case to indicate that the node is the root, and
must be treated specially.
> 一个节点完成工作，需要三个阶段，两个到达，一个combine

The CombiningTree’s getAndIncrement() method has four phases.
> 多出来的phase : distribute

```java
  public int getAndIncrement() throws InterruptedException {
    Stack<Node> stack = new Stack<Node>();
    Node myLeaf = leaf[ThreadID.get() / 2];
    Node node = myLeaf;
    // phase one
    while (node.precombine()) {
      // 如果可以precombine 那么持续向上!
      node = node.parent;
    }
    Node stop = node;
    // The stop variable is set to the last node visited,
    // which is either the last node at which the thread arrived second, or the root.


    // phase two
    node = myLeaf;
    int combined = 1;
    while (node != stop) {
      // 从下到上逐步combine内容吗 ?
      // 如果其中是 first 那么不管，如果是second 加上 second 的内容，
      // 那么如果采用
      combined = node.combine(combined);
      stack.push(node); // 从下向上node 的内容其实是确定的，但是保存一下，问题不大。
      node = node.parent;
    }
    // phase 3
    int prior = stop.op(combined);


    // phase 4
    while (!stack.empty()) {
      node = stack.pop();
      node.distribute(prior);
    }
    return prior;
  }
```

```java
  synchronized boolean precombine() throws InterruptedException {
    while (locked) wait();
    switch (cStatus) {
      case IDLE:
        cStatus = CStatus.FIRST;
        return true;
      case FIRST:
        locked = true;
        // 唯一lock 的位置: earlier process : combining with the thread's value
        // 由于外层锁的出现，导致每一个node只有一个线程可以进入 ! 而且所有的操作都是正常的
        // 如果不添加，第三个线程进入，那么就一定会导致 unexpected Node state 的状态，也就是首先需要等到前面结合完成之后后面的才可以操作。

        // Before it returns, the thread places a long-term lock on the node (by setting locked to true)
        // to prevent the earlier visiting thread from proceeding without combining with the thread’s value
        cStatus = CStatus.SECOND;
        return false;
      case ROOT:
        return false;
      default:
        throw new PanicException("unexpected Node state " + cStatus);
    }
  }

  synchronized int combine(int combined) throws InterruptedException {
    while (locked) wait();
    locked = true;
    firstValue = combined;
    switch (cStatus) {
      case FIRST:
        return firstValue;
      case SECOND:
        return firstValue + secondValue;
      default:
        throw new PanicException("unexpected Node state " + cStatus);
    }
  }
```

In the combining phase, the thread revisits the nodes
it visited in the precombining phase, *combining its value with values left by other
threads*. It stops when it arrives at the node stop where the precombining phase
ended. Later on, we traverse these nodes in reverse order, so as we go we push the
nodes we visit onto a stack.
> 似乎是在收割，**撞**到我的路径上的人。
> 一共三次遍历

#### 12.3.2 An Extended Example

#### 12.3.3 Performance and Robustness
> skip

## 12.4 Quiescently Consistent Pools and Counte
Not all applications require linearizable counting. Indeed, counter-based **Pool**
implementations require only quiescently consistent
counting: all that matters
is that the counters produce no duplicates and no omissions.

## 12.5 Counting Networks
In the same way, combining trees must be tightly coordinated: if requests do not arrive together, the algorithm does not work efficiently,
no matter how fast the individual processes

#### 12.5.1 Networks That Count
A balancer is said to be **quiescent** if every token that arrived on an input wire has
emerged on an output wire:
x0 + x1 = y0 + y1

On a shared-memory multiprocessor, however, a balancing network can
be implemented as an object in memory. Each balancer is an object, whose wires
are references from one balancer to another. Each thread repeatedly traverses the
object, starting on some input wire, and emerging at some output wire, effectively shepherding a token through the network

We can _check for ourselves_ that if any number of tokens enter the network, in
any order, on any set of input wires, then they emerge in a regular pattern on the
output wires. Informally, no matter how token arrivals are distributed among the
input wires, the output distribution is balanced across the output wires, *where
the top output wires are filled first*.

#### 12.5.2 The Bitonic Counting Network
正确性证明: merger 的性质是什么 ? 当上半部分 和 下半部分 分别满足 step property 那么输出满足。


* **A Periodic Counting Network**
In this section, we show that the Bitonic network is not the only counting network
with depth O(log2w). We introduce a new counting network with the remarkable property that it is periodic, consisting of a sequence of identical subnetworks,
as depicted in Fig. 12.18.

A `LAYER [w]` network joins input wires `i` and `w − i − 1` to the same balancer.

balancer 构成 layer ，进而构成block 进而构成 periodic

> 证明，应该是采用类似的方法，只是想要说明，构成网络的方法不唯一。

#### 12.5.3 Performance and Pipelining
For a fixed network width, throughput rises
with the number of threads up to a point, and then the network saturates, and
throughput remains constant or declines. To understand these results, let us think
of a counting network as a pipeline.

## 12.6 Diffracting Trees
Can we design a logarithmic-depth counting network? The good news
is yes, such networks exist, but the bad news is that for all known constructions,
the *constant factors* involved render these constructions impractical.

Prism :
1. 持有 Exchanger 数组和random变量
2. visit函数: 采用类似之前的stack的方法，在 Exchanger 数组中间随机查找其他人，如果遇到其中。

DiffractingBalancer :
1. When a thread calls
`traverse()`, it tries to find a partner through the prism. If it succeeds, then the
partners return with distinct values, without creating contention at the `toggle`
Otherwise, if the thread is unable to find a partner, it traverses (Line 16)
the toggle (implemented as a balancer)
2. `DiffractingBalancer` has a capacity, which is actually the capacity of its internal prism. Initially this capacity is the size of the tree, and the capacity shrinks by
half at each level

> 其实，采用 Exchanger 的原因只是为了减少blancer 的 contension 而已。
> 因为其实，两个thread 访问，那么最终导致 balancer 的状态恢复到原来的情况

## 12.7 Parallel Sorting
As most Computer Science
undergraduates learn early on, the choice of sorting algorithm depends crucially
on the number of items being sorted, the numerical properties of their keys, and
whether the items reside in memory or in an external storage device. Parallel
sorting algorithms can be classified in the same way.

We present two classes of sorting algorithms: sorting networks, which typically
work well for *small in-memory* data sets, and sample sorting algorithms, which
work well for large data sets in *external memory*. In our presentation, we sacrifice
performance for simplicity. More complex techniques are cited in the chapter
notes.

## 12.8 Sorting Networks
#### 12.8.1 Designing a Sorting Network
There is no need to design sorting networks, because we can recycle counting network layouts. A balancing network and a comparison network are isomorphic if
one can be constructed from the other by replacing balancers with comparators,
or vice versa.

Theorem 12.8.2. If a balancing network counts, then its isomorphic comparison
network sorts.
> 当将blancer 换成 comparator，那么就可以实现从counter 切换为 sorter

1. 在 sort 上输入 10 相当于在 count 的端口上进行10次计数 ? (应该不是使用这一个模型)
2. If a sorting network sorts every input sequence of 0s and 1s, then it sorts any sequence of input values.
> 如果一个sorting 网络可以对于0 1 序列排序，那么该网络可以对于任何输入排序进行排序。(姑且认为是真的)


A comparator, unlike a balancer, is synchronous: it outputs values only when both inputs have arrived.

Take any arbitrary sequence of 0s and 1s as inputs to the comparison network,
and for the balancing network place *a token on each 1 input wire* and *no token on each 0 input wire*.

If we run both networks in *lock-step*, the balancing network simulates the comparison network.

The converse is false: not all sorting networks are counting networks.

> 当进行排序的使用一组01序列，相当于对应序号thread要进行排序，那么最后，最后输出网络中间必然可以得到一组内容而且是排序好的
> 接下来需要证明是 : 采用 comparator 构成的网络，两者每层工作方式相同。所以 comparator 的输出的结果也是排序的。
> balancer 遇到两个taken comparator 遇到两个1.
> 需要保证，当进行访问的时候，所有的节点总是只能访问一次才可以。



为什么说 counter 是可以 count 的?
1. 入口处为数字大小，thread id ? (是thread id , 其实从哪一个位置上进入关系不打 !)
2. step property 为什么可以保证可以实现计数 ?
3. counter.java::traverse 的实现莫名奇妙 (实现的确是有问题，书上的基本对的，但是也有问题)

Threads traverse the counting network to choose which counters to access.

Any balancing network that satisfies the step property is called a counting network, because it can easily be adapted to count the number of tokens that have
traversed the network.
Counting is done, as we described earlier in Fig. 12.9, by
adding a *local counter* to each output wire i, so that tokens emerging on that wire
are assigned consecutive numbers i,i + w, . . . ,i + (yi − 1)w.
> 并不是进行一个统计工作，而是，当一个thread 从 network 的一头走到另一个位置的时候，那么traverse返回值告知其所在的位置以及
> 所以输出位置必须持有一个local counter，那么该thread 就知道自己添加上去的时候，计数器的数值到达了多少。

> 所以为什么不是可线性化的 ?
> 利用讲义的例子，首先，两个蓝色的首先进入，卡着，然后红色计入，得到计数为3, 然后黄色进入，得到计数为０，因为
> 红色和黄色是含有偏序关系的，但是结果还是相反，所以不成立。


* ***A Bitonic Sorting Algorithm***

We can represent any width-w sorting network, such as `BITONIC [w]`, as a collection of d layers of `w/2` balancers each.

We can represent a sorting network
layout as a table, where each entry is a pair that describes which two wires meet
at that balancer at that layer.

Each of the p threads emulates the work of s comparators. Unlike counting
networks, which act like uncoordinated raves, sorting networks are synchronous:
all inputs to a comparator must arrive before it can compute the outputs. The
algorithm proceeds in rounds. **In each round**, a thread performs s comparisons
in a layer of the network, switching the array entries of items if necessary, so that
they are properly ordered. In each network layer, the comparators join different
wires, so no two threads attempt to exchange the items of the same entry, avoiding the need to synchronize operations at any given layer.
> 每一轮，进行s次数的比较!


To ensure that the comparisons of a given round (layer) are complete before
proceeding to the next one, we use a synchronization construct called a Barrier

An in-place array-based sorting algorithm takes as *input* an array of items to
be sorted (here we assume these items have unique integer keys) and returns
the *same array* with the items sorted by key.

Let us assume that we wish to sort an array of 2 · p · s elements,
where p is the number of threads (and typically also the maximal number of
available processors on which the threads run) and p · s is a power of 2. The
network has p · s comparators at every layer

> 算法的内容是科学的，但是不知道和bionic balancer 的关系是什么 ?
> 1. north 和 south 的数值是什么 ? 数组的下标
> 2. 构成的网络其实总是覆盖到每一层的，就可以，所以其结构的确是 : period的结构
> 3. 其实 sort 的过程非常的简单，就是分 thread 处理自己所在区域，进行移动即可!

> 回顾一下证明的内容 : 因为是sort 数据是一层层的通过的，当数据从head 到 tail 一次即可 !
> 似乎很早的时候，就知道网络是成为层次的，不会指向k+2 的位置。

## 12.9 Sample Sorting
Since the data set to be sorted is large, we split it into buckets, throwing into
each bucket the items that *have keys* within a given range. Each thread then sorts
the items in one of the buckets using a sequential sorting algorithm, and the result
is a sorted set (when viewed in the appropriate bucket order). This algorithm is
a generalization of the well-known quicksort algorithm, but instead of having a
single splitter key to divide the items into two subsets, we have p − 1 splitter keys
that split the input set into p subsets
> 划分为三个步骤

## 问题
